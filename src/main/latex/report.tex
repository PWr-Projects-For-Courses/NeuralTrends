\documentclass[11pt,a4paper,oneside]{report}

\usepackage[MeX]{polski}
%\usepackage[utf8]{inputenc}
\usepackage{graphicx}

\usepackage{fontspec}
\usepackage[table,xcdraw]{xcolor}

% Dodane przeze mnie d
\usepackage{fancyvrb} % dla srodowiska Verbatim
\usepackage{color}
\usepackage{colortbl}
\usepackage{lscape}

\usepackage{tabularx}
\usepackage{nicefrac}

\usepackage{algpseudocode}
\usepackage[chapter]{algorithm}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{multirow}
\usepackage{longtable}

\usepackage[english, polish]{babel}

\definecolor{stal}{rgb}{0.75, 0.75, 0.75}

\newcommand{\todo}{\colorbox{red}}

\begin{document}

\title{Techniki heurystycznego uczenia warstw ukrytych w sieci głębokiej}
\author{inż. Jacek Miszczak \\ inż. Filip Malczak}
\date{3.06.2015}
\maketitle

\begin{abstract}
Praca ta opisuje wykorzystanie technik heurystycznej optymalizacji do nauki deterministycznych autokoderów operujących na danych ciągłych. Przedstawiono tu powody niepowodzenia podczas zastosowania stosu autokoderów do problemu rozpoznawania oraz porównanie różnych metod nauki deterministycznych autokoderów w problemie redukcji wymiarowości danych ciągłych. Zbadano skuteczność nauki za pomocą propagacji wstecznej, heurystyk w postaci algorytmów genetycznych oraz algorytmów rojowych, a także podejścia mieszane wykorzystującego oba z wymienionych rozwiązań. Na podstawie wyników badań podejścia heurystyczne można uznać za mniej efektywne od algorytmu propagacji wstecznej dla rozważanego problemu.

\end{abstract}

\tableofcontents

\chapter{Wstęp}

Niniejszy raport jest podsumowaniem projektu realizowanego w ramach kursu ,,Nowe trendy w obliczeniach neuronowych'' którego temat brzmiał ,,Techniki heurystycznego uczenia warstw ukrytych w sieci głębokiej''. Od czytelnika oczekuje się podstawowej znajomości dziedziny sieci neuronowych i obliczeń miękkich. Bardziej szczegółowy opis zastosowanych technik znajduje się w rozdziale \ref{chap:introduction}.

Pierwotnym celem projektu było zbadanie alternatywnego podejścia do uczenia sieci głębokich. Miało ono polegać na zbudowaniu stosu autokoderów (opisanych w sekcji \ref{sec:autoencoders}), uczonych w dwóch krokach. Pierwszym z nich miała być zastosowanie popularnej metody propagacji wstecznej. Niestandardową częścią uczenia był krok drugi, polegający na wykorzystaniu heurystyk optymalizacyjnych (konkretnie algorytmów ewolucyjnych i rojowych) w celu poprawienia jakości działania wstępnie wyuczonej sieci.

Zamierzenia tego nie udało się zrealizować, czego powody zostały opisane w rozdziale \ref{chapter:david-bowie}. Aby w ramach tego projektu odkryć nową wiedzę nt. sieci neuronowych i ich uczenia, zdecydowano się na zmianę tematu.

Nowym celem projektu zostało zbadanie jakości uczenia pojedynczego autokodera przy użyciu podejścia heurystycznego i mieszanego. Wyniki dla alternatywnych metod nauki porównano z metodą propagacji wstecznej.

\chapter{Wprowadzenie}
\label{chap:introduction}

W rozdziale tym przedstawiono zagadnienia i podejścia wykorzystane podczas realizacji projektu, którego podsumowaniem jest ten raport. Założono, że czytelnik jest zaznajomiony z podstawowymi pojęciami dotyczącymi zagadnienia sieci neuronowych, takimi jak pojęcie warstw wejściowych, ukrytych i wyjściowych, algorytm propagacji wstecznej bądź wagi pomiędzy neuronami. Skupiono się tutaj na zagadnieniach nowych w dziedzinie oraz takich spoza dziedziny obliczeń neuronowych.

\section{Autokodery i stosy autokoderów}
\label{sec:autoencoders}

Autokodery (\textit{ang. autoencoders}) stanowią jedną ze stosowanych architektur głębokich sieci neuronowych. Znajdują one zastosowanie zarówno w redukcji wymiarowości danych jak i w odnajdywaniu ich wewnętrznej, ukrytej reprezentacji. 

Pojedynczy autokoder jest trójwarstwową siecią neuronową, której celem jest odtwarzanie na wyjściu danych zadanych na wejściu \cite{hinton2006reducing}. W związku z tym rozmiar warstwy wyjściowej jest równy rozmiarowi warstwy wejściowej. Rozmiar warstwy ukrytej zależy od przeznaczenia projektowanego autokodera -- wykorzystanie warstwy mniejszej od warstwy wejściowej skutkuje otrzymaniem sieci potrafiącej zredukować wymiarowość danych, co może być także wykorzystane do zadania kompresji. Gdy warstwa ukryta jest większa, to sieć taka powinna nauczyć się wewnętrznej reprezentacji danych.

Wykorzystanie pojedynczego autokodera do znacznej redukcji wymiarowości danych jest jednak nieefektywne. Gdy różnica pomiędzy rozmiarami warstwy wejściowej a warstwy ukrytej jest zbyt duża, to nauczenie sieci poprawnego odtwarzania tak mocno zredukowanych wzorców jest trudne. Rozwiązaniem tego problemu jest idea stosu autokoderów. Polega ona na zbudowaniu sieci neuronowej z większa liczbą warstw ukrytych, gdzie kolejne warstwy mają coraz mniejsze rozmiary. Różnica rozmiarów pomiędzy kolejnymi warstwami jest tym samym mniejsza.

Aby wykorzystać stos autokoderów do odtwarzania należy utworzyć sieć zawierająca nieparzystą liczbę warstw ukrytych, których rozmiary są symetryczne. Dzięki temu można wskazać na środkową warstwę ukrytą, najmniejszą ze wszystkich, zawierającą zredukowane dane. Warstwę taką nazywa się warstwą kodu. Warstwy leżące pomiędzy warstwą wejściową, a warstwą kodu, włącznie z wymienionymi, nazywa się koderem (\textit{ang. encoder}). Dekoder (\textit{ang. decoder}) zaś stanowią warstwy od warstwy kodu do warstwy wyjściowej.

Zarówno pojedyncze autokodery jak ich stosy można uczyć za pomocą propagacji wstecznej za błąd przyjmując dowolną funkcję rozbieżności danych wejściowych i wyjściowych, jak na przykład błąd średniokwadratowy. Uczenie sieci z dużą liczbą warstw ukrytych za pomocą propagacji wstecznej jest jednak nieefektywne \cite{hinton2006reducing} z powodu dyfuzji gradientu. Aby rozwiązać ten problem stosowane jest podejście znane z sieci DBN (\textit{Deep Belief Network}) \cite{le2008representational}. Polega ono na oddzielnym uczeniu pojedynczych, trójwarstwowych, autokoderów. 

W każdym etapie takiej nauki autokoder uczony jest odtwarzać dane zadane na wejściu nie zważając na resztę sieci. Wejściem warstwy $n$ jest jednak wyjście warstwy $n-1$. Tym samym pierwsza warstwa ukryta uczona jest rekonstrukcji danych z warstwy wejściowej całej sieci. Aby było to możliwe należy utworzyć jeszcze jedną warstwę o rozmiarze takim samym jak warstwa wejściowa. Po zakończeniu nauki pojedynczej warstwy odłączana jest dodana wcześniej warstwa wykorzystywana podczas nauki. Już nauczone wagi między warstwą wejściową a ukrytą są zapamiętywane. Następnie algorytm zaczyna naukę kolejnej warstwy, która tym razem musi nauczyć się rekonstrukcji danych uzyskanych z wcześniejszej warstwy ukrytej.

Poza kompresją i redukcją wymiarowości danych stosy autokoderów znajdują także zastosowanie w innych zadaniach z dziedziny maszynowego uczenia, takich jak rozpoznawanie czy opisywanie. Czyni się to poprzez eliminację warstw stanowiących dekoder, zamiast nich dołączając po warstwie kodu algorytm odpowiedni do rozważanego zadania. Może to być przykładowo klasyfikator, także w formie perceptronu zachowując tym samym neuronową naturę stosowanego rozwiązania. Algorytm taki operuje na danych o zredukowanej wymiarowości stanowiących swego rodzaju wewnętrzną reprezentację oryginalnych danych. 

\section{Algorytmy genetyczne}

Ewolucja to proces zachodzący w naturze odpowiedzialny za dopasowywanie się osobników danego gatunku do środowiska w jakim żyją. Podstawą tego procesu jest przetrwanie lepiej przystosowanych osobników, dziedziczenie i mutacja.

Przetrwanie lepiej przystosowanych osobników to zasada zgodnie z którą osobniki lepiej dopasowane do środowiska mają większą szansę na przeżycie, a co za tym idzie, na wydanie potomstwa. Oznacza to, że rodzice większości osobników z kolejnego pokolenia będą radzić sobie w tym środowisku lepiej niż pozostałe osobniki z ich pokolenia.

Dziedziczenie to zjawisko przekazywania cech rodziców dzieciom. Odbywa się ono podczas rozmnażania, a więc zachodzi między dwojgiem rodziców, a potomstwem. Kod genetyczny potomstwa tworzony jest przez losowe łączenie odpowiednich części kodu genetycznego rodziców, przez co kolejne pokolenie dzieli ich cechy. W ten sposób losowe osobniki przejmą od rodziców te cechy, które pozwalały im się dopasować do środowiska i w niektórych przypadkach pozwoli im to na jeszcze lepsze dopasowanie się do otoczenia. Część osobników przejmie jednak nie tylko cechy poprawiające ich szansę przetrwania, ale również cechy negatywne, co przełoży się na ich gorsze dopasowanie.

Mutacja to zjawisko zachodzenia losowych zmian w kodzie genetycznym osobnika, przez które ma on szansę zyskać nowe cechy, które w niektórych przypadkach doprowadzą do lepszego dopasowania. Osobniki z przypadkowymi zmianami, które poprawiają ich dopasowanie mają większe szanse na przeżycie i wydanie potomstwa, \textit{ergo} przypadkowe pozytywne zmiany powinny zostać rozpropagowane wśród osobników przyszłych pokoleń.

Algorytmy ewolucyjne to rodzina heurystyk naśladujących proces ewolucji w celu optymalizacji \cite{davis1991handbook}. Pojedynczy punkt w przestrzeni rozwiązań jest w nich nazywany osobnikiem. Osobniki możemy między sobą porównywać pod względem wartości optymalizowanej funkcji dla nich, a relacja mniejszości (dla problemów minimalizacji) lub większości (dla problemów maksymalizacji) reprezentuje relację bycia lepiej przystosowanym do środowiska. Ponadto, na osobnikach określone są operatory mutacji i krzyżowania, które mają na celu kolejno symulację losowych zmian w osobniku i tworzenie nowych osobników na podstawie starych. Heurystyka polega na wielokrotnym przetworzeniu populacji (czyli zbioru osobników) poprzez zastosowanie każdego z operatorów z pewnym prawdopodobieństwem. W każdym kroku (nazywanym w nomeklaturze algorytmów ewolucyjnych pokoleniem) do dotychczasowej populacji dołączane są wyniki działania tych operatorów (czyli zbiory osobników zmutowanych i potomstwa), a następnie wybierana jest nowa populacja, używana w kolejnym kroku. Aby odwzorować zasadę przetrwania najlepiej dopasowanych osobników do kolejnej populacji wybierane są z wyższym prawdopodobieństwem osobniki lepiej przystosowane.


\section{Particle Swarm Optimization}

Kolejna heurystyką wzorowaną na naturze jest optymalizacja za pomocą roju cząsteczek (\textit{ang. Particle Swarm Optimization, PSO}). Zainspirowana została ona przez obserwację zachowań stad zwierząt, w szczególności ptaków i owadów. Jej celem jest osiągnięcie inteligencji obliczeniowej poprzez wykorzystanie analogii interakcji społecznych w przeciwieństwie do odwzorowywania zdolności kognitywnych jednostki \cite{poli2007particle}. 

W metodzie PSO pewna liczba bytów (cząsteczek) jest umieszczana w D-wymiarowej przestrzeni rozwiązań rozważanego problemu. Każda z takich pozycji reprezentuje jedno z możliwych rozwiązań. Następnie każda cząsteczka ewaluuje optymalizowaną funkcję celu w swojej obecnej pozycji. W kolejnym, kluczowym, kroku działania heurystyki dla wszystkich cząsteczek obliczany jest wektor przemieszczenia na podstawie rozwiązania obecnego, najlepszych rozwiązań znalezionych zarówno przez obecnie rozważany byt jak i przez cały rój oraz pewnego czynnika losowego. Po przemieszczeniu wszystkich cząsteczek rozpoczyna się kolejna iteracja. W miarę upływu czasu cały rój, analogicznie do stada ptaków wspólnie poszukujących pożywienia, zbliży się do globalnego optimum funkcji celu. Metoda kończy swoje działanie gdy osiągnięty zostanie warunek stopu, w najprostszym przypadku reprezentowany przez limit liczby iteracji. 

Każda cząsteczka modelowana jest jako 3 wektory D-wymiarowe, gdzie D jest liczbą wymiarów przeszukiwanej przestrzeni rozwiązań:

\begin{itemize}
\item $\vec{x}_{i}$ - obecna pozycja,
\item $\vec{p}_{i}$ - historycznie najlepsza pozycja,
\item $\vec{v}_{i}$ - prędkość.
\end{itemize}

Obecna pozycja $\vec{x}_{i}$ może być rozumiana jako współrzędne reprezentujące pozycję w przestrzeni. W każdej iteracji algorytmu obecna pozycja jest ewaluowana jako możliwe rozwiązanie problemu. Jeśli ta pozycja okaże się lepsza od wszystkich znalezionych wcześniej, to jej koordynaty zapisywane są w wektorze $\vec{p}_{i}$, a wartość funkcji celu w zmiennej $pbest_{i}$. Celem jest odszukiwanie coraz lepszych pozycji i aktualizowanie $\vec{p}_{i}$ oraz $pbest_{i}$. Nowa pozycja obliczana jest poprzez dodanie wektora prędkości $\vec{v}_{i}$ do pozycji $\vec{x}_{i}$ i algorytm działa poprzez modyfikację $\vec{v}_{i}$.

Rój cząsteczek stanowi coś więcej niż tylko kolekcję pojedynczych cząsteczek. Pojedynczy byt nie posiada niemalże żadnych możliwości rozwiązania zadanego problemu, rozwój odbywa się poprzez interakcję cząsteczek. Byty ułożone są według pewnej topologii komunikacji w sąsiedztwa \cite{kennedy2010particle}. Najprostszym wariantem jest sąsiedztwo globalne, w którym wszystkie cząsteczki mogą się ze sobą komunikować. 

W procesie optymalizacji rojem cząsteczek prędkość każdego z bytów jest iteratywnie modyfikowana tak, by cząsteczki stochastycznie oscylowały wokół pozycji $\vec{p}_{i}$ oraz $\vec{p}_{g}$, gdzie $\vec{p}_{g}$ oznacza najlepsze rozwiązanie znalezione przez byty należące do sąsiedztwa rozważanej cząstki $i$.

Modyfikacja wektora prędkości odbywa się według wzoru przedstawionego w równaniu \eqref{eq:pso_v} \cite{poli2007particle}:

\begin{equation}
\label{eq:pso_v}
\vec{v}_{i} = \vec{rand}(0, \varPhi_{1}) \otimes (\vec{p}_{i} - \vec{x}_{i}) + \vec{rand}(0, \varPhi_{2}) \otimes (\vec{p}_{g} - \vec{x}_{i}).
\end{equation}

Notacja:

\begin{itemize}
\item $\vec{rand}(0, \varPhi_{i})$ oznacza wektor losowych liczb równomiernie rozłożonych na $[0, \varPhi_{i}]$. Jest on generowany losowo w każdej iteracji i dla każdej cząsteczki,
\item $\otimes$ oznacza operację mnożenia wektorów zdefiniowaną w następujący sposób: $[x_0, x_1, \ldots, x_n] \otimes [y_0, y_1, \ldots, y_n] = [x_0 y_0,  x_1 y_1, \ldots, x_n y_n]$,
\item $\varPhi_{i}$ oznacza siłę wpływu czynnika losowego na poruszanie się cząsteczek.
\end{itemize}

\chapter{Powody zmiany celu}

\label{chapter:david-bowie} %ch-ch-ch-chaaaangeees...

%jak miało być, co miało być badane

%co i czemu nei pykło

%co robimy teraz, konkretnie

Pierwotnym celem projektu było zbadanie skuteczności stosu autokoderów w problemie opisywania obiektów przy uczeniu z wykorzystaniem heurystyk oraz propagacji wstecznej. Już na wczesnym etapie wykonywania badań stwierdzono jednak, iż problemy występujące w stosowanych rozwiązaniach uniemożliwiają uzyskanie miarodajnych wyników. Zdecydowano się tym samym na zmianę celu wykonywania projektu i idei badań. 

W rozdziale tym opisano powody zmiany celu pracy oraz przedstawiono nowy cel.

\section{Pierwotny cel}

Pierwotnym celem było zastosowanie głębokich stosów autokoderów z dodaną warstwą klasyfikującą w postaci perceptronu do problemu opisywania obiektów. Dla przypomnienia: zadanie opisywania, znane także jako klasyfikacja wieloklasowa, polega na przypisaniu obiektowi na podstawie jego obserwacji pewnego podzbioru etykiet ze ściśle ustalonego zbioru. Najbardziej oczywistym przykładem takiego problemu jest zagadnienie opisywania obrazów, czyli określenia, jakie obiekty występują na obrazie i przypisanie mu etykiet odpowiadających tym obiektom. 

Uczenie głębokich sieci neuronowych z pomocą algorytmu propagacji wstecznej jest bardzo czasochłonne, szczególnie gdy wykorzystywane jest podejście do zachłannego uczenia poszczególnych warstw opisane w sekcji \ref{sec:autoencoders}. Pierwotnym celem było wykorzystanie podejść heurystycznych oraz mieszanych (wykorzystujących zarówno propagację wsteczną jak i heurystyki) celem przyspieszenia procesu nauki sieci oraz zwiększenia jej skuteczności w problemie rozpoznawania. Skuteczność tak uczonych sieci (reprezentowana przez miarę F) miała zostać porównana z sieciami uczonymi jedynie z pomocą propagacji wstecznej.

Wykorzystane miało zostać podejście oparte o uczenie zachłanne -- pojedyncze autokodery były uczone indywidualnie, ale po pewnej liczbie epok propagacji wstecznej (także zerowej) wykorzystywano podejście oparte o heurystykę do dalszej optymalizacji wag. W analogiczny sposób uczona była warstwa ostatnia, klasyfikująca.

Przykład opisywania obrazów został wcześniej podany nie bez powodu -- zamierzano skorzystać ze zbioru danych \textit{corel5k} \cite{alcala2010keel} reprezentującego właśnie problem opisywania obrazów.

\section{Napotkane problemy}

Zamierzano wykorzystać zbiór danych zawierający jedynie atrybuty o wartościach binarnych, tj należących do zbioru $\lbrace 0, 1 \rbrace$. Wybrano tym samym zbiór \textit{corel5k} zawierający 5000 obiektów reprezentowanych przez 499 cech binarnych i opisanych z pomocą 374-elementowego zbioru etykiet. Szybko natknięto się jednak na ograniczenie natury technicznej -- w wykorzystywanej bibliotece do obliczeń neuronowych \textit{encog} liczba wag pomiędzy warstwami zapisywana była w zmiennej typu \textit{Integer}. Dla tak dużej liczby cech oraz połączeń typu każdy-z-każdym realna liczba wag przekraczała dopuszczalny zakres dla zmiennej tego typu.

Zdecydowano się tym samym wykorzystać zbiór danych, w którym instancje opisane są z pomocą mniejszej liczby cech. Nie znaleziono jednak zbioru zawierającego mniej cech binarnych. Zrezygnowano tym samym z ograniczenia na typ cech i wykorzystano zbiór \textit{emotions} \cite{alcala2010keel} zawierający 593 obiekty reprezentowane przez 72 cechy rzeczywistoliczbowe, i opisane z pomocą 6 etykiet. Przed wykorzystaniem tych danych w sieci neuronowej wymagane było wykonanie normalizacji wartości cech, czyli takie ich przekształcenie, by mieściły się w zakresie (0, 1). Było to możliwe dzięki podanym w zbiorze danych dziedzinom kolejnych cech.

Wymóg operowania na znormalizowanych danych bierze się z tego, iż w autokoderach używane były sigmoidalne funkcje aktywacji których przeciwdziedziną jest przedział (0, 1). Autokoder taki nie jest w stanie odtworzyć wartości spoza tego zakresu.

Zmiana wykorzystywanego zbioru danych poskutkowała jednak tym, iż wykorzystywane autokodery miały za zadanie odtwarzać wartości rzeczywiste, co jest zadaniem trudniejszym niż odtwarzanie wartości pochodzących z dwuelementowego zbioru. Wstępne badania pokazały, że skuteczność odtwarzania takich wartości nie jest zadowalająca przy wykorzystaniu dotychczasowej architektury. Aby rozwiązać ten problem zdecydowano się wykorzystać metodę nauki paczkami (\textit{ang. batch learning}) \cite{ngiam2011optimization}. Dane używane podczas nauki podzielono na paczki zawierające nie więcej niż 50 instancji i proces nauki z wykorzystaniem propagacji wstecznej powtarzano osobno dla każdej paczki. Pozwoliło to poprawić wyniki i uzyskać zadowalającą dokładność rekonstrukcji dla pojedynczego autokodera.

Niestety podczas układania autokoderów w stosy na jaw wyszedł kolejny problem. O ile pojedynczy autokoder odtwarzał zadane wartości rzeczywiste z niewielkim błędem, to w dużej mierze była to zasługa precyzyjnie dobranych wag w warstwie dekodującej. Zaobserwowano, że dla jednej zadanej instancji wszystkie neurony w warstwie kodu zapalały się dokładnie w tym samym stopniu -- ich funkcje aktywacji przyjmowały takie same wartości. Pomiędzy różnymi wektorami wartości wejściowych wartości aktywacji się od siebie różniły, ale zawsze wewnątrz jednego przykładu do rekonstrukcji wszystkie neurony przyjmowały takie same wartości. 

Tym samym każdy z przykładów uczących był efektywnie reprezentowany tylko przez jedną liczbę. O ile możliwe jest nauczenie klasyfikatora korzystając z takiej reprezentacji by w miarę poprawnie opisywał obiekty należące do zbioru danych uczących, to nie oferowało to zdolności generalizacji na nieznane obiekty, czyli te wchodzące w skład zbioru testowego.

Dalsza redukcja wymiarowości danych mijała się tym samym z celem. Już drugi autokoder w stosie miał bardzo proste zadanie -- odtwarzał efektywnie tylko jedną wartość zamiast wektora różnych wartości. W związku z tym aktywacje neuronów w drugiej warstwie kodu były zbliżone do zera i niezmiennie wszystkie przyjmowały takie same wartości dla jednego przypadku uczącego. 

Ostateczne opisywanie w warstwie klasyfikującej wykorzystując tak ,,nauczony'' stos autokoderów okazało się gorsze od losowego -- zależnie od losowego czynnika sterującego początkowymi wagami sieci wszystkie instancje były opisywane albo wszystkimi etykietami, albo żadną z nich. Wyniki te były stałe niezależnie od użytych parametrów liczby epok propagacji wstecznej, rozmiarów oraz liczby warstw ukrytych. 

Dalsze przeprowadzanie eksperymentów było tym samym bezcelowe -- na dobrą sprawę wyniki były znane jeszcze przed uruchomieniem eksperymentu.

Aby praca ta jednak wnosiła wartość dodaną i dostarczała nowej wiedzy zdecydowano się na modyfikację jej celu.


\section{Nowy cel pracy}

Za nowy cel pracy przyjęto zbadanie efektywności metod heurystycznych oraz mieszanych w uczeniu pojedynczego autokodera mającego za zadanie odtwarzać wartości ciągłe z zakresu $(0, 1)$. Aby nie operować na wygenerowanych danych losowych skorzystano tutaj z danych stanowiących znormalizowane cechy obiektów z opisanego wcześniej zbioru \textit{emotions}, co pozwala ocenić skuteczność autokodera w kompresji i rekonstrukcji realnych danych. 

Skupiono się tym samym na zadaniu kompresji poprzez redukcję wymiarowości. Rozmiar warstwy ukrytej ustawiono na $0,75$ rozmiaru warstwy wejściowej. Dla wykorzystanego zbioru danych rozmiar ten wynosi tym samym:

\begin{equation}
\lfloor 0,75 \times 72 \rfloor = 54 .
\end{equation}

Autokoder uczony jest z pomocą propagacji wstecznej z zastosowaniem regularyzacji L2 i uczenia za pomocą paczek oraz poprzez zastosowanie podejść heurystycznych. Użyte w badaniach heurystyki to algorytm genetyczny oraz optymalizacja roju cząsteczek. Zostały one opisane w rozdziale \ref{chap:introduction}. 

W pierwszej kolejności autokoder jest uczony za pomocą algorytmu propagacji wstecznej przez pewną liczbę epok uczenia, która jest jednym z badanych parametrów. Następnie wszystkie wagi takiej sieci, zarówno te pomiędzy warstwą wejściową i ukrytą, jak i te między warstwą ukrytą a wyjściową, zbierane są do pojedynczego wektora wartości liczbowych. Wektor taki jest następnie wykorzystywany w heurystykach jako genom, czyli reprezentacja osobnika. Ocena konkretnego rozwiązania podczas optymalizacji heurystycznej jest dokonywana przez zbudowanie sieci na podstawie zadanych wag, wykorzystanie jej do kompresji i rekonstrukcji danych treningowych oraz obliczenie błędu średniokwadratowego uzyskanej rekonstrukcji. 

\chapter{Badania}

W rozdziale tym przedstawiono opis przeprowadzonych badań. W pierwszej jego części opisano cel wykonanych badań oraz podział zbioru testowego w celu wykonania walidacji krzyżowej. Następnie przedstawiono plan badań, tj. zakresy zbadanych parametrów. Następnie opisana została realizacja technik uczenia, tj. parametry propagacji wstecznej i elementy heurystyk które należało zdefiniować. W ostatniej części rozdziału przedstawiono uzyskane wyniki badań.

\section{Cel badań}

Nie jest możliwa analityczna weryfikacja skuteczności zaproponowanych metod uczenia. W związku z tym przeprowadzono badania mające na celu porównanie heurystycznych metod nauki autokoderów z ugruntowanym podejściem opartym o propagację wsteczną.

\section{Zbiór danych i walidacja krzyżowa}

Zbiór danych został pobrany z repozytorium danych KEEL \cite{alcala2010keel}. Poza zbiorem w czystej postaci udostępniono go tam także wstępnie podzielonego na 5 par zbiorów uczących i testowych, przygotowanych do wykorzystania podczas przeprowadzania procedury walidacji krzyżowej.

\section{Zbadane parametry}

W tabeli \ref{table:params} zostały przedstawione zakresy badanych parametrów.

W przypadku korzystania z algorytmu ewolucyjnego używano prawdopodobieństwa mutacji dobieranego automatycznie przez bibliotekę \emph{Opt4J}.

Eksperymenty wykonano dla każdej kombinacji wykorzystywanych parametrów.

\begin{table}[H]
	\caption{Zbadane zakresy parametrów \label{table:params}}
	\begin{tabularx}{\linewidth}{|l|c|X|}
		\hline
		\textbf{Parametr} & \textbf{Zakres wartości} & \textbf{Znaczenie parametru}\\
		\hline \hline
		\textit{epochs} & $[0, 1000, 2000, 3000]$ & Łączna liczba epok propagacji wstecznej\footnotemark[1]. Jeśli wartość tego parametru wynosiła 0, to technika ta w ogóle nie była stosowana. \\
		\hline
		\textit{generations} & $[0, 100, 200, 500]$ & Ilość pokoleń w algorytmie ewolucyjnym lub iteracji w algorytmie rojowym. Jeśli wartość tego parametru wynosiła 0, to heurystyka w ogóle nie była używana w procesie uczenia. \\
		\hline
		\textit{population} & $[100, 200, 500]$ &  Ilość rozwiązań przetwarzanych przez heurystykę w ramach jednej iteracji. Zarówno PSO jak i EA są heurystykami populacyjnymi, więc mimo różnego nazewnictwa, obie są parametryzowane tą wartością. Jeśli liczba iteracji wynosiła 0, to ten parametr nie był używany. \\
		\hline
		\textit{cp} & $[0,5, 0,75, 0,9]$	& Parametr używany jedynie w sytuacji, w której korzystaliśmy z algorytmu ewolucyjnego. Określa prawdopodobieństwo tego, że losowy osobnik z populacji weźmie udział w operacji krzyżowania. \\
		\hline
	\end{tabularx}
\end{table}

\footnotetext[1]{Naukę propagacją wsteczną prowadzono paczkami po 50 instancji uczących, co dla zbioru uczącego dawało 10 paczek. Wartość tego parametru to liczba epok wykonana dla wszystkich paczek. Innymi słowy, przy użyciu każdej z nich wykonywano \nicefrac{1}{10} wszystkich epok. }

\section{Realizacja technik uczenia}

Przy korzystaniu z propagacji wstecznej korzystano z regularyzacji L2 \cite{girosi1995regularization} ze współczynnikiem 0.1. Miało to na celu wymuszenie kodowania rzadkiego w autokoderze \cite{ngiam2011optimization}.

Obie heurystyki służyły do dobrania jak najlepszych wag w pojedynczym autokoderze. Zestawy wag były reprezentowane jako wektory liczb zmiennoprzecinkowych, będące połączonymi wektorami wag między warstwą ukrytą, a wejściową oraz wyjściową, a ukrytą. Wagi były uporządkowane w wektorze w następujący sposób:

\begin{displaymath}
	[ h_{0, 0}, h_{0, 1}, \ldots, h_{1, 0}, h_{1, 1}, \ldots, o_{0, 0}, o_{0, 1}, \ldots, o_{1, 0}, o_{1, 1}, \ldots ]
\end{displaymath}

gdzie $h_{i, j}$ oznacza wagę połączenia między $i$tym neuronem warstwy ukrytej i $j$tym neuronem warstwy wejściowej, a $o_{i, j}$ analogiczną wagę między warstwą wyjściową i ukrytą.

Początkowy zbiór rozwiązań dla każdej z heurystyk uzyskiwano poprzez losową modyfikację rozwiązania uzyskanego przez zastosowanie propagacji wstecznej. Jeśli technika ta nie była stosowana, to rozwiązania były generowane losowo, przez wybranie losowych wag z przedziału $\left\langle -\infty, \infty \right\rangle $. Sama modyfikacja polegała na przemnożeniu każdej wagi przez losowy współczynnik z zakresu $\left\langle 0.8, 1.2 \right\rangle $, wybierany według rozkładu równomiernego.

Użyto standardowych operatorów genetycznych dla osobników reprezentowanych przez wektory liczbowe. Operator mutacji modyfikował losowe pozycje w wektorze przez dodanie do nich losowych wartości. Operator krzyżowania został zaimplementowany jako proste krzyżowanie jednopunktowe.

Jako operator selekcji zastosowano implementację opartą o algorytm NSGA-II \cite{deb2002fast}. Operator ten dla pojedynczego kryterium sprowadza się do operatora elitystycznego, zwracającego najlepsze osobniki z dotychczasowej populacji.

Funkcją oceny używaną w heurystykach optymalizacyjnych był błąd średniokwadratowy (\textit{ang. mean squared error, MSE}) rekonstrukcji całego zbioru treningowego.

\section{Wyniki}

W dalszej części raportu do konkretnych metod uczenia będziemy odnosić się przy pomocy ich angielskich akronimów. Są one przedstawione w tabeli \ref{table:acronyms}.

\begin{table}[H]
	\caption{Oznaczenia metod uczenia używanego w raporcie \label{table:acronyms}}
	\begin{tabularx}{\linewidth}{|c|X|X|}
		\hline
		Akronim & Nazwa angielska & Nazwa polska \\
		\hline \hline
		BP & Backpropagation & Propagacja wsteczna \\ \hline
		EA & Evolutionary Algorithm & Algorytm ewolucyjny \\ \hline
		PSO & Particle Swarm Optimization & Algorytm rojowy \\ \hline
		BP+EA & Backpropagation with Evolutionary Algorithm & Propagacja wsteczna z algorytmem ewolucyjnym \\ \hline
		BP+PSO & Backpropagation with Particle Swarm Optimization & Propagacja wsteczna z algorytmem rojowym \\ \hline
	\end{tabularx}
\end{table}


\begin{table}[H]
	\caption{Porównanie efektywności różnych metod uczenia \label{table:compare}. Dla każdej metody przedstawiono 3 najlepsze wyniki uzyskane podczas przeprowadzania badań.}
	\centering 
	\begin{longtable}{|l|r@{$\pm$}r|}
		\hline
		Metoda uczenia & \multicolumn{2}{|c|}{Ocena} \\
		\hline \hline
		\multirow{3}{*}{BP} & 0,0228 & 0,0011 \\ 
		 & 0,0235 & 0,0019 \\ 
		 & 0,0235 & 0,0007 \\ \hline
		\multirow{3}{*}{EA} & 0,3087 & 0,0278 \\ 
		 & 0,3103 & 0,0042 \\ 
		 & 0,3109 & 0,0124 \\ \hline
		\multirow{3}{*}{PSO} & 0,3025 & 0,0272 \\ 
		 & 0,3123 & 0,0271 \\ 
		 & 0,3271 & 0,0277 \\ \hline
		\multirow{3}{*}{BP+EA} & 0,0230 & 0,0014 \\
		 & 0,0236 & 0,0032 \\
		 & 0,0238 & 0,0017 \\ \hline
		\multirow{3}{*}{BP+PSO} & 0,0237 & 0,0021 \\
		 & 0,0237 & 0,0004 \\
		 & 0,0269 & 0,0071 \\ \hline
	\end{longtable}
\end{table}

W tabeli \ref{table:compare} zaprezentowano po 3 najlepsze wyniki uzyskane dla każdej z badanych metod podczas wykonywania wszystkich badań, niezależnie od wartości parametrów. Najlepsze z tych wyników przedstawiono także na wykresie znajdującym się na rysunku \ref{figure:compare}.

Jak można zaobserwować, podejścia wykorzystujące jedynie heurystyki bez wcześniejszej nauki za pomocą propagacji wstecznej uzyskały wyniki dużo gorsze od pozostałych rozwiązań. Wykorzystanie heurystyk do dalszej nauki sieci wstępnie nauczonej za pomocą propagacji spowodowało nieznaczne pogorszenie uzyskanych wyników.

Spośród zbadanych heurystyk algorytm optymalizacji z pomocą roju cząsteczek pozwolił uzyskać wyniki odrobinę lepsze niż te uzyskane podczas stosowania algorytmu ewolucyjnego. Wiąże się to jednak z dużo większym czasem nauki. 

Zmierzone czasy nauki za pomocą badanych metod nie są niestety miarodajne ze względu na wykonywanie badań na dwóch różnych maszynach o różnej mocy obliczeniowej, dlatego też nie zostały one w tej pracy zamieszczone. Można je jednak wykorzystać do oszacowania jak czasochłonna jest nauka. Propagacja wsteczna wykonywała się w ciągu kilku sekund, algorytm genetyczny potrzebował kilkunastu minut by zakończyć obliczenia, a PSO aż kilkunastu godzin.

\begin{figure}[H]
	\caption{Wykres efektywności różnych metod uczenia \label{figure:compare}}
	\input{gnuplot/methods.tex}
\end{figure}

\subsection{Propagacja wsteczna}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia BP w zależności od liczby epok \label{figure:bp_epochs}}
	\input{gnuplot/bp_epochs.tex}
\end{figure}

Na rysunku \ref{figure:bp_epochs} przedstawiono wykres błędu popełnianego przez autokoder nauczony z pomocą propagacji wstecznej w zależności od liczby epok uczenia. Można zauważyć, że błąd maleje wraz ze wzrostem liczby epok do pewnego momentu, a później rośnie. Można podejrzewać, że wiąże się to z kwestią przeuczenia (\textit{ang. overfitting}) sieci -- błąd na danych treningowych wciąż maleje, jednak sieć staje się zanadto dopasowana do tych danych i wykorzystanie osobnego zbioru danych testowych powoduje uzyskanie wyższego błędu.

\subsection{Algorytm ewolucyjny}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia EA w zależności od liczby pokoleń \label{figure:ea_generations}}
	\input{gnuplot/ea_generations.tex}
\end{figure}

Na rysunku \ref{figure:ea_generations} przedstawiono wykres błędu uzyskanego przez sieć nauczona za pomocą algorytmu genetycznego w zależności od liczby pokoleń zastosowanej w tym algorytmie. Można zauważyć, że z początku błąd ten rośnie, co wiąże się ze stochastyczną naturą zastosowanego podejścia, ale ostatecznie w miarę zwiększania liczby pokoleń błąd stopniowo maleje. 

Wykres \ref{figure:ea_population} przedstawia zależność błędu od rozmiaru populacji. Z początku błąd ten maleje, ale od pewnego momentu zaczyna rosnąć. Wiąże się to najprawdopodobniej z szerokim zakresem możliwych wartości, jakie mogą przyjmować kolejne wagi optymalizowane z pomocą tego algorytmu. Duży rozmiar populacji powoduje utworzenie wielu złych rozwiązań, które następnie w wyniku krzyżowania pogarszają ostateczny wynik.

Na wykresie \ref{figure:ea_cp} zaprezentowano zależność błędu od użytego prawdopodobieństwa krzyżowania. Najlepszy wynik został osiągnięty dla najniższego prawdopodobieństwa spośród badanych. To także najprawdopodobniej wiąże się z zastosowaniem szerokiego zakresu możliwych wartości wag.

\begin{figure}[H]
	\caption{Wykres efektywności uczenia EA w zależności od rozmiaru populacji \label{figure:ea_population}}
	\input{gnuplot/ea_population.tex}
\end{figure}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia EA w zależności od prawd. krzyżowania \label{figure:ea_cp}}
	\input{gnuplot/ea_cp.tex}
\end{figure}

\subsection{Algorytm rojowy}

Na wykresach \ref{figure:pso_generations} oraz \ref{figure:pso_population} przedstawiono błąd popełniany przez sieć nauczoną z pomocą algorytmu PSO w zależności od liczby iteracji oraz liczby cząsteczek. W miarę zwiększania liczby iteracji wynik się coraz bardziej poprawiał, jednak wiązało się to ze znacznym wydłużeniem czasu nauki -- nawet do kilkunastu godzin. Analogicznie, zwiększanie rozmiaru populacji powoduje spadek błędu.

\begin{figure}[H]
	\caption{Wykres efektywności uczenia PSO w zależności od liczby iteracji \label{figure:pso_generations}}
	\input{gnuplot/pso_generations.tex}
\end{figure}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia PSO w zależności od liczby cząsteczek \label{figure:pso_population}}
	\input{gnuplot/pso_population.tex}
\end{figure}

\subsection{Propagacja wsteczna + Algorytm ewolucyjny}

Na wykresach \ref{figure:bp_ea_epochs} - \ref{figure:bp_ea_cp} przedstawiono błąd popełniany przez sieć uczoną z pomocą podejścia mieszanego wykorzystującego propagację wsteczną oraz algorytm ewolucyjny w zależności od parametrów tych metod. Obserwacje dotyczące liczby epok pozostają takie same jak w przypadku czystej propagacji wstecznej. 

Zwiększanie liczby pokoleń algorytmu genetycznego powoduje ostateczną poprawę uzyskanego wyniku. W przeciwieństwie jednak do czystego algorytmu ewolucyjnego zwiększanie rozmiaru populacji w podejściu mieszanym powoduje spadek błędu. Wiąże się to z tym, iż populacja początkowa budowana jest na podstawie prototypu uzyskanego dzięki propagacji wstecznej przez co zakres możliwych wag się znacznie zmniejsza. 

Wyższe wartości prawdopodobieństwa krzyżowania powodują poprawę wyników do pewnego momentu, za wysokie jednak powodują zwiększenie błędu. Wiąże się to z tym, iż przy prawdopodobieństwie rzędu 90\% krzyżowanie jest niemalże pewne i powoduje nadmierne wymieszanie osobników.

\begin{figure}[H]
	\caption{Wykres efektywności uczenia BP+EA w zależności od liczby epok \label{figure:bp_ea_epochs}}
	\input{gnuplot/bp_ea_epochs.tex}
\end{figure}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia BP+EA w zależności od liczby pokoleń \label{figure:bp_ea_generations}}
	\input{gnuplot/bp_ea_generations.tex}
\end{figure}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia BP+EA w zależności od rozmiaru populacji \label{figure:bp_ea_population}}
	\input{gnuplot/bp_ea_population.tex}
\end{figure}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia BP+EA w zależności od prawd. krzyżowania \label{figure:bp_ea_cp}}
	\input{gnuplot/bp_ea_cp.tex}
\end{figure}

\subsection{Propagacja wsteczna + Algorytm rojowy}

Wykresy \ref{figure:bp_pso_epochs} - \ref{figure:bp_pso_population} przedstawiają wyniki uzyskane przez sieć nauczoną za pomocą podejścia mieszanego wykorzystującego propagację wsteczną oraz algorytm PSO w zależności od parametrów obu tych rozwiązań częściowych. 

W miarę zwiększania liczby epok propagacji wstecznej błąd maleje. Nie można już tutaj zaobserwować zjawiska przeuczenia. Wiąże się to najprawdopodobniej z tym, iż zastosowany algorytm rojowy pogarszał odrobinę wyniki uzyskane przez propagację wsteczną, eliminując tym samym efekt przeuczenia.

W miarę wzrostu liczby iteracji algorytmu rojowego błąd się zwiększa. Jest to prawdopodobnie efektem tego, iż dzięki zastosowaniu propagacji wstecznej heurystyka rozpoczyna przeszukiwanie przestrzeni od rozwiązań bliskich do optymalnego. Dalsze losowe przeszukiwanie przestrzeni powoduje tylko pogorszenie uzyskanych wyników. 

Wyniki pozostają na zbliżonym poziomie niezależnie od rozmiaru populacji. Nagły wzrost błędu dla populacji o rozmiarze 200 można uzasadnić stochastyczną naturą podejścia heurystycznego.

\begin{figure}[H]
	\caption{Wykres efektywności uczenia BP+PSO w zależności od liczby epok \label{figure:bp_pso_epochs}}
	\input{gnuplot/bp_pso_epochs.tex}
\end{figure}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia BP+PSO w zależności od liczby iteracji \label{figure:bp_pso_generations}}
	\input{gnuplot/bp_pso_generations.tex}
\end{figure}

\begin{figure}[H]
	\caption{Wykres efektywności uczenia BP+PSO w zależności od liczby cząsteczek \label{figure:bp_pso_population}}
	\input{gnuplot/bp_pso_population.tex}
\end{figure}

\chapter{Podsumowanie}

Ostateczny cel projektu, tj. porównanie skuteczności wybranych metod uczenia został zrealizowany.

Najlepsze wyniki uzyskano przy użyciu standardowej propagacji wstecznej z wykorzystaniem regularyzacji L2. 
Próba poprawy skuteczności autokodera przy pomocy metod heurystycznych w ogólności pogarszała wyniki. 

Uczenie przy pomocy samego algorytmu ewolucyjnego dawało mało satysfakcjonującą jakość rekonstrukcji, z błędem większym (w porównaniu do klasycznego podejścia) o rząd wartości. 
Użycie algorytmu rojowego bez propagacji dawało wyniki porównywalne do algorytmu ewolucyjnego, jednak wraz ze wzrostem liczby literacji ocena rozwiązania była coraz lepsza. 

Duży błąd rekonstrukcji przy użyciu metod heurystycznych może wynikać z bardzo dużej przestrzeni rozwiązań. 
Osobniki lub cząsteczki były reprezentowane jako wektory wag, z których każda mogła być dowolną liczbą rzeczywistą.
Jeśli przeszukiwanie przestrzeni rozpoczynaliśmy od rozwiązań znalezionych przez metodę propagacji wstecznej, to heurystyka szybko pogarszała wyniki.

Problemem okazał się również długi czas uczenia - sama propagacja wsteczna trwała sekundy, algorytm ewolucyjny - minuty, a rojowy - godziny. 
Być może po o wiele większej ilości iteracji algorytm rojowy zaczynający od losowych rozwiązań dorównałby standardowej propagacji wstecznej, jednak różnice w długości trwania sprawiają, że nie nadaje się on do rzeczywistych zastosowań.

Można zauważyć, że najlepsze wyniki (poza przypadkiem BP+EA) osiągano dla 2000 epok propagacji wstecznej, a dla mniejszej lub większej ilości epok błąd rekonstrukcji nieznacznie rósł. 
Może to wynikać z niedouczenia (dla mniejszej liczby epok) lub przeuczenia (dla większej liczby epok) sieci.

W ramach projektu wykazano, że dla problemu rekonstrukcji danych o cechach ciągłych uczenie propagacją wsteczną daje znacząco lepsze wyniki niż metody heurystyczne. 
Dalsze badania mogłyby zwalidować tą tezę dla danych o atrybutach dyskretnych i dla innych realizacji heurystyk, tj. innych reprezentacji osobników i cząsteczek i innych operatorów.

\bibliographystyle{plain}
\bibliography{bibliografia}

\appendix 
\chapter{Pełne wyniki badań}

W tabelach przedstawionych w tym rozdziale kolumna \textit{Ocena} zawiera wartości średniego MSE dla konfiguracji opisanych pozostałymi kolumnami, wraz z odchyleniem standardowym.

\section{Propagacja wsteczna}

\begin{center}
	\begin{longtable}{|r|r@{$\pm$}r|}
		\hline
		\multicolumn{1}{|c|}{Liczba epok} & \multicolumn{2}{|c|}{Ocena}\\ \hline \hline\endhead
		1000 & 0,0235 & 0,0019 \\ \hline
		2000 & 0,0228 & 0,0011\\ \hline
		3000 & 0,0235 & 0,0007\\ \hline
	\end{longtable}
\end{center}

\section{Algorytm ewolucyjny}

\begin{center}
	\begin{longtable}{|l|l|l|r@{$\pm$}r|}
		\hline
		Liczba & Rozmiar & Prawd. & \multicolumn{2}{|c|}{Ocena}\\
		pokoleń & populacji & krzyżowania & \multicolumn{2}{|c|}{}\\ \hline \hline\endhead
		100 & 100 & 0,50 & 0,3223 & 0,0201\\ \hline
		100 & 100 & 0,75 & 0,3315 & 0,0081\\ \hline
		100 & 100 & 0,90 & 0,3191 & 0,0235\\ \hline
		100 & 200 & 0,50 & 0,3087 & 0,0278\\ \hline
		100 & 200 & 0,75 & 0,3286 & 0,0266\\ \hline
		100 & 200 & 0,90 & 0,3134 & 0,0117\\ \hline
		100 & 500 & 0,50 & 0,3207 & 0,0096\\ \hline
		100 & 500 & 0,75 & 0,3356 & 0,0158\\ \hline
		100 & 500 & 0,90 & 0,3224 & 0,0104\\ \hline
		200 & 100 & 0,50 & 0,3113 & 0,0177\\ \hline
		200 & 100 & 0,75 & 0,3344 & 0,0289\\ \hline
		200 & 100 & 0,90 & 0,3362 & 0,0179\\ \hline
		200 & 200 & 0,50 & 0,3249 & 0,0216\\ \hline
		200 & 200 & 0,75 & 0,3163 & 0,0156\\ \hline
		200 & 200 & 0,90 & 0,3139 & 0,0231\\ \hline
		200 & 500 & 0,50 & 0,3132 & 0,0241\\ \hline
		200 & 500 & 0,75 & 0,3109 & 0,0124\\ \hline
		200 & 500 & 0,90 & 0,3265 & 0,0066\\ \hline
		500 & 100 & 0,50 & 0,3202 & 0,0101\\ \hline
		500 & 100 & 0,75 & 0,3151 & 0,0120\\ \hline
		500 & 100 & 0,90 & 0,3410 & 0,0290\\ \hline
		500 & 200 & 0,50 & 0,3172 & 0,0225\\ \hline
		500 & 200 & 0,75 & 0,3257 & 0,0177\\ \hline
		500 & 200 & 0,90 & 0,3103 & 0,0042\\ \hline
		500 & 500 & 0,50 & 0,3293 & 0,0308\\ \hline
		500 & 500 & 0,75 & 0,3342 & 0,0225\\ \hline
		500 & 500 & 0,90 & 0,3284 & 0,0277\\ \hline
	\end{longtable}
\end{center}

\section{Algorytm rojowy}

\begin{center}
	\begin{longtable}{|l|l|r@{$\pm$}r|}
		\hline
		Liczba iteracji & Liczba cząsteczek & \multicolumn{2}{|c|}{Ocena}\\ \hline \hline\endhead
		100 & 100 & 0,3368 & 0,0230\\ \hline
		100 & 200 & 0,3360 & 0,0170\\ \hline
		100 & 500 & 0,3296 & 0,0090\\ \hline
		200 & 100 & 0,3284 & 0,0392\\ \hline
		200 & 200 & 0,3275 & 0,0188\\ \hline
		200 & 500 & 0,3271 & 0,0277\\ \hline
		500 & 100 & 0,3025 & 0,0272\\ \hline
		500 & 200 & 0,3285 & 0,0133\\ \hline
		500 & 500 & 0,3123 & 0,0271\\ \hline
	\end{longtable}
\end{center}

\section{Propagacja wsteczna + Algorytm ewolucyjny}

\begin{center} 
	\begin{longtable}{|l|l|l|l|r@{$\pm$}r|}
		\hline
		Liczba & Liczba & Rozmiar & Prawd. & \multicolumn{2}{|c|}{Ocena} \\
		epok & pokoleń & populacji & krzyżowania & \multicolumn{2}{|c|}{}\\ \hline \hline\endhead
		1000 & 100 & 100 & 0,50 & 0,0439 & 0,0206\\ \hline
		1000 & 100 & 100 & 0,75 & 0,0518 & 0,0196\\ \hline
		1000 & 100 & 100 & 0,90 & 0,0497 & 0,0178\\ \hline
		1000 & 100 & 200 & 0,50 & 0,0255 & 0,0018\\ \hline
		1000 & 100 & 200 & 0,75 & 0,0387 & 0,0185\\ \hline
		1000 & 100 & 200 & 0,90 & 0,0446 & 0,0181\\ \hline
		1000 & 100 & 500 & 0,50 & 0,0355 & 0,0065\\ \hline
		1000 & 100 & 500 & 0,75 & 0,0305 & 0,0097\\ \hline
		1000 & 100 & 500 & 0,90 & 0,0350 & 0,0075\\ \hline
		2000 & 100 & 100 & 0,50 & 0,0330 & 0,0175\\ \hline
		2000 & 100 & 100 & 0,75 & 0,0314 & 0,0156\\ \hline
		2000 & 100 & 100 & 0,90 & 0,0459 & 0,0281\\ \hline
		2000 & 100 & 200 & 0,50 & 0,0350 & 0,0060\\ \hline
		2000 & 100 & 200 & 0,75 & 0,0252 & 0,0028\\ \hline
		2000 & 100 & 200 & 0,90 & 0,0279 & 0,0043\\ \hline
		2000 & 100 & 500 & 0,50 & 0,0273 & 0,0045\\ \hline
		2000 & 100 & 500 & 0,75 & 0,0230 & 0,0014\\ \hline
		2000 & 100 & 500 & 0,90 & 0,0256 & 0,0019\\ \hline
		3000 & 100 & 100 & 0,50 & 0,0238 & 0,0017\\ \hline
		3000 & 100 & 100 & 0,75 & 0,0427 & 0,0021\\ \hline
		3000 & 100 & 100 & 0,90 & 0,0271 & 0,0007\\ \hline
		3000 & 100 & 200 & 0,50 & 0,0236 & 0,0032\\ \hline
		3000 & 100 & 200 & 0,75 & 0,0350 & 0,0019\\ \hline
		3000 & 100 & 200 & 0,90 & 0,0301 & 0,0022\\ \hline
		3000 & 100 & 500 & 0,50 & 0,0348 & 0,0023\\ \hline
		3000 & 100 & 500 & 0,75 & 0,0393 & 0,0030\\ \hline
		3000 & 100 & 500 & 0,90 & 0,0344 & 0,0014\\ \hline
		1000 & 200 & 100 & 0,50 & 0,0374 & 0,0129\\ \hline
		1000 & 200 & 100 & 0,75 & 0,0562 & 0,0322\\ \hline
		1000 & 200 & 100 & 0,90 & 0,0785 & 0,0381\\ \hline
		1000 & 200 & 200 & 0,50 & 0,0358 & 0,0093\\ \hline
		1000 & 200 & 200 & 0,75 & 0,0443 & 0,0120\\ \hline
		1000 & 200 & 200 & 0,90 & 0,0413 & 0,0104\\ \hline
		1000 & 200 & 500 & 0,50 & 0,0309 & 0,0103\\ \hline
		1000 & 200 & 500 & 0,75 & 0,0312 & 0,0049\\ \hline
		1000 & 200 & 500 & 0,90 & 0,0383 & 0,0210\\ \hline
		2000 & 200 & 100 & 0,50 & 0,0507 & 0,0096\\ \hline
		2000 & 200 & 100 & 0,75 & 0,0530 & 0,0418\\ \hline
		2000 & 200 & 100 & 0,90 & 0,0544 & 0,0163\\ \hline
		2000 & 200 & 200 & 0,50 & 0,0320 & 0,0078\\ \hline
		2000 & 200 & 200 & 0,75 & 0,0467 & 0,0307\\ \hline
		2000 & 200 & 200 & 0,90 & 0,0640 & 0,0377\\ \hline
		2000 & 200 & 500 & 0,50 & 0,0292 & 0,0067\\ \hline
		2000 & 200 & 500 & 0,75 & 0,0289 & 0,0028\\ \hline
		2000 & 200 & 500 & 0,90 & 0,0259 & 0,0041\\ \hline
		3000 & 200 & 100 & 0,50 & 0,0347 & 0,0050\\ \hline
		3000 & 200 & 100 & 0,75 & 0,0284 & 0,0029\\ \hline
		3000 & 200 & 100 & 0,90 & 0,0264 & 0,0033\\ \hline
		3000 & 200 & 200 & 0,50 & 0,0400 & 0,0038\\ \hline
		3000 & 200 & 200 & 0,75 & 0,0868 & 0,0001\\ \hline
		3000 & 200 & 200 & 0,90 & 0,0632 & 0,0007\\ \hline
		3000 & 200 & 500 & 0,50 & 0,0455 & 0,0019\\ \hline
		3000 & 200 & 500 & 0,75 & 0,0299 & 0,0021\\ \hline
		3000 & 200 & 500 & 0,90 & 0,0328 & 0,0034\\ \hline
		1000 & 500 & 100 & 0,50 & 0,0583 & 0,0120\\ \hline
		1000 & 500 & 100 & 0,75 & 0,0492 & 0,0260\\ \hline
		1000 & 500 & 100 & 0,90 & 0,0765 & 0,0278\\ \hline
		1000 & 500 & 200 & 0,50 & 0,0681 & 0,0294\\ \hline
		1000 & 500 & 200 & 0,75 & 0,0510 & 0,0151\\ \hline
		1000 & 500 & 200 & 0,90 & 0,0592 & 0,0315\\ \hline
		1000 & 500 & 500 & 0,50 & 0,0271 & 0,0040\\ \hline
		1000 & 500 & 500 & 0,75 & 0,0320 & 0,0091\\ \hline
		1000 & 500 & 500 & 0,90 & 0,0501 & 0,0189\\ \hline
		2000 & 500 & 100 & 0,50 & 0,0522 & 0,0190\\ \hline
		2000 & 500 & 100 & 0,75 & 0,0771 & 0,0346\\ \hline
		2000 & 500 & 100 & 0,90 & 0,0834 & 0,0292\\ \hline
		2000 & 500 & 200 & 0,50 & 0,0328 & 0,0102\\ \hline
		2000 & 500 & 200 & 0,75 & 0,0501 & 0,0374\\ \hline
		2000 & 500 & 200 & 0,90 & 0,0590 & 0,0251\\ \hline
		2000 & 500 & 500 & 0,50 & 0,0246 & 0,0019\\ \hline
		2000 & 500 & 500 & 0,75 & 0,0392 & 0,0139\\ \hline
		2000 & 500 & 500 & 0,90 & 0,0307 & 0,0126\\ \hline
		3000 & 500 & 100 & 0,50 & 0,0391 & 0,0012\\ \hline
		3000 & 500 & 100 & 0,75 & 0,0554 & 0,0014\\ \hline
		3000 & 500 & 100 & 0,90 & 0,1305 & 0,0021\\ \hline
		3000 & 500 & 200 & 0,50 & 0,0562 & 0,0005\\ \hline
		3000 & 500 & 200 & 0,75 & 0,0969 & 0,0032\\ \hline
		3000 & 500 & 200 & 0,90 & 0,0704 & 0,0028\\ \hline
		3000 & 500 & 500 & 0,50 & 0,0714 & 0,0041\\ \hline
		3000 & 500 & 500 & 0,75 & 0,0739 & 0,0022\\ \hline
		3000 & 500 & 500 & 0,90 & 0,0694 & 0,0023\\ \hline
	\end{longtable}
\end{center}

\section{Propagacja wsteczna + Algorytm rojowy}
\begin{center}
	\begin{longtable}{|l|l|l|r@{$\pm$}r|}
		\hline
		Liczba epok & Liczba iteracji & Liczba cząsteczek & \multicolumn{2}{|c|}{Ocena}\\ \hline \hline\endhead
		1000 & 100 & 100 & 0,0276 & 0,0081\\ \hline
		1000 & 100 & 200 & 0,0479 & 0,0265\\ \hline
		1000 & 100 & 500 & 0,0621 & 0,0233\\ \hline
		2000 & 100 & 100 & 0,0269 & 0,0071\\ \hline
		2000 & 100 & 200 & 0,0433 & 0,0255\\ \hline
		2000 & 100 & 500 & 0,0628 & 0,0179\\ \hline
		3000 & 100 & 100 & 0,0237 & 0,0021\\ \hline
		3000 & 100 & 200 & 0,0482 & 0,0003\\ \hline
		3000 & 100 & 500 & 0,0486 & 0,0010\\ \hline
		1000 & 200 & 100 & 0,0394 & 0,0223\\ \hline
		1000 & 200 & 200 & 0,0540 & 0,0234\\ \hline
		1000 & 200 & 500 & 0,0455 & 0,0251\\ \hline
		2000 & 200 & 100 & 0,0469 & 0,0224\\ \hline
		2000 & 200 & 200 & 0,0419 & 0,0164\\ \hline
		2000 & 200 & 500 & 0,0404 & 0,0164\\ \hline
		3000 & 200 & 100 & 0,0388 & 0,0020\\ \hline
		3000 & 200 & 200 & 0,0488 & 0,0034\\ \hline
		3000 & 200 & 500 & 0,0237 & 0,0004\\ \hline
		1000 & 500 & 100 & 0,0443 & 0,0246\\ \hline
		1000 & 500 & 200 & 0,0572 & 0,0299\\ \hline
		1000 & 500 & 500 & 0,0422 & 0,0286\\ \hline
		2000 & 500 & 100 & 0,0323 & 0,0146\\ \hline
		2000 & 500 & 200 & 0,0479 & 0,0231\\ \hline
		2000 & 500 & 500 & 0,0749 & 0,0012\\ \hline
		3000 & 500 & 100 & 0,0493 & 0,0007\\ \hline
		3000 & 500 & 200 & 0,0749 & 0,0018\\ \hline
		3000 & 500 & 500 & 0,0684 & 0,0027\\ \hline
	\end{longtable}
\end{center}


\end{document}